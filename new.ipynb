{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@params\n",
    "    df: a dataframe from which the null columns are to be removied\n",
    "    threshold: the total count of nulls in the column to decide whether to remove that column or not\n",
    "@returns:\n",
    "    dataframe with deleted columns based on the threshold from the provided dataframe 'df'\n",
    "'''\n",
    "def removeableCols(df,threshold):\n",
    "    count_null = sum(pd.isnull(df[df.columns]),axis=0)\n",
    "    return count_null[count_null > threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 251)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "#print(df.dtypes)\n",
    "#df = pd.get_dummies(df)\n",
    "#remove columns\n",
    "removColList = removeableCols(df,50)\n",
    "df = df.drop(removColList,axis=1)\n",
    "\n",
    "#split dataframe into two with categorical and continuous\n",
    "cats = [col for col,x in df.dtypes.items() if x == 'object']\n",
    "cat_df = df[cats]\n",
    "\n",
    "cont_df = df.drop(cats,axis=1)\n",
    "cat_df = cat_df.fillna(cat_df.mode(axis=0))\n",
    "\n",
    "#create dictionary of columns to their modes for\n",
    "#categorical data\n",
    "modemaps = cat_df.mode(axis=0).to_dict()\n",
    "for k in modemaps:\n",
    "    modemaps[k] = modemaps[k][0]\n",
    "#print(modemaps)\n",
    "\n",
    "#create dictionary of columns to their median for\n",
    "#continuous data\n",
    "cont_df = cont_df.fillna(cont_df.median())\n",
    "medianmaps = cont_df.median(axis=0).to_dict()\n",
    "#print(medianmaps)\n",
    "\n",
    "#for k in medianmaps:\n",
    " #   medianmaps[k] = medianmaps[k][0]\n",
    "#print(medianmaps)\n",
    "cat_df = pd.get_dummies(cat_df)\n",
    "combined_df = pd.concat((cont_df,cat_df),axis=1)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 235)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "test_df = test_df.drop(removColList,axis=1)\n",
    "\n",
    "#split dataframe into cont and cat\n",
    "cat_test_df = test_df[cats]\n",
    "cont_test_df = test_df.drop(cats,axis=1)\n",
    "cat_test_df = cat_test_df.fillna(value=modemaps)\n",
    "cat_test_df = pd.get_dummies(cat_test_df)\n",
    "\n",
    "cont_test_df = cont_test_df.fillna(value=medianmaps)\n",
    "\n",
    "combined_test_df = pd.concat((cont_test_df,cat_test_df),axis=1)\n",
    "combined_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 235)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the columns from training data which are not present\n",
    "#test data\n",
    "not_found_cols = list(set(combined_df.columns)-set(combined_test_df.columns))\n",
    "y = combined_df['SalePrice']\n",
    "combined_df = combined_df.drop(not_found_cols,axis=1)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RFG\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "rfg = RFG(100)\n",
    "rfg.fit(combined_df,y)\n",
    "gbr = GBR()\n",
    "gbr.fit(combined_df,y)\n",
    "y_pred = (rfg.predict(combined_test_df) + gbr.predict(combined_test_df))/2\n",
    "#y_pred = gbr.predict(combined_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test_df['Id'],pd.Series(y_pred,name='SalePrice')],axis=1)\n",
    "submission.to_csv('dataset/submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "try to run the gradient boosting algorithm with all the strings replaced\n",
    "with the numbers and then try that out it should definitely work pretty well \n",
    "and we should gain some point on that\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
