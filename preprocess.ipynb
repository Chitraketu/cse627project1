{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis program parses the description file,\\nin order to map all the string of categorical attributes to an integer\\nso that they can be treated as numerical attribute\\nand then removes the columns which have more than 100 nulls \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "this program parses the description file,\n",
    "in order to map all the string of categorical attributes to an integer\n",
    "so that they can be treated as numerical attribute\n",
    "and then removes the columns which have more than 100 nulls \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "@params:\n",
    "    filename: a filename of the description.txt from kaggle competition describing each columns of dataset\n",
    "@returns:\n",
    "    dictionary of mapping for each string type of categorical values for each column with an integer\n",
    "'''\n",
    "def buildJSON(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        d = dict()\n",
    "        temp = ''\n",
    "        count = 0\n",
    "        for l in f:\n",
    "            if l.strip() == '':continue\n",
    "            if ':' in l:\n",
    "                temp = l.split(':')[0]\n",
    "                d[temp] = dict()\n",
    "                count = 0\n",
    "            else:\n",
    "                lst = l.strip().split('\\t')\n",
    "                try:\n",
    "                    int(lst[0])\n",
    "                except ValueError:\n",
    "                    d[temp][lst[0]] = count\n",
    "                count += 1\n",
    "    return d\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@params\n",
    "    df: a dataframe from which the null columns are to be removied\n",
    "    threshold: the total count of nulls in the column to decide whether to remove that column or not\n",
    "@returns:\n",
    "    dataframe with deleted columns based on the threshold from the provided dataframe 'df'\n",
    "'''\n",
    "def removeNullCols(df,threshold):\n",
    "    count_null = sum(pandas.isnull(df[df.columns]),axis=0)\n",
    "    return df[count_null[count_null < threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'dataset/data_description.txt'\n",
    "d = buildJSON(filename)\n",
    "df = pandas.read_csv('dataset/train.csv')\n",
    "processed_df = removeNullCols(df,50)\n",
    "processed_df = processed_df.replace(d)\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\AppData\\Local\\conda\\conda\\envs\\cse627\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "C:\\Users\\chitr\\AppData\\Local\\conda\\conda\\envs\\cse627\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "processed_df = processed_df.fillna(processed_df.median(axis=0))\n",
    "y = processed_df['SalePrice']\n",
    "X = processed_df.drop('SalePrice',axis=1)\n",
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "processed_df = processed_df.fillna(processed_df.median(axis=0))\n",
    "y = processed_df['SalePrice']\n",
    "X = processed_df.drop('SalePrice',axis=1)\n",
    "cols = X.columns\n",
    "#sum(pandas.isna(processed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\AppData\\Local\\conda\\conda\\envs\\cse627\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 289)\n",
      "728 732\n",
      "2592427878.8825135\n",
      "732 predicted array's length\n",
      "(1156, 289)\n",
      "1156 304\n",
      "421100526.2524487\n",
      "304 predicted array's length\n",
      "(1258, 289)\n",
      "1258 202\n",
      "400033097.2775504\n",
      "202 predicted array's length\n",
      "(1329, 289)\n",
      "1329 131\n",
      "870154386.6345707\n",
      "131 predicted array's length\n",
      "(1369, 289)\n",
      "1369 91\n",
      "439729766.1415779\n",
      "91 predicted array's length\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "tdf = pandas.get_dummies(df)\n",
    "tdf = tdf.fillna(tdf.median(axis=0))\n",
    "ty = tdf['SalePrice']\n",
    "tX = tdf.drop('SalePrice',axis=1)\n",
    "for train_index, test_index in skf.split(tX, ty):\n",
    "    X_train, X_test = tX.iloc[train_index], tX.iloc[test_index]\n",
    "    y_train, y_test = ty.iloc[train_index], ty.iloc[test_index]\n",
    "    print(X_train.shape)\n",
    "    print(len(X_train),len(X_test))\n",
    "    r1 = RandomForestRegressor(50)\n",
    "    r1.fit(X_train,y_train)\n",
    "    ty_test = r1.predict(X_test)\n",
    "    print(mse(y_test,ty_test))\n",
    "    print(len(ty_test),'predicted array\\'s length')\n",
    "    \n",
    "#sum(pandas.isna(X[X.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\AppData\\Local\\conda\\conda\\envs\\cse627\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 69)\n",
      "2519850091.4385247\n",
      "(1156, 69)\n",
      "399204821.4493043\n",
      "(1258, 69)\n",
      "394386821.6488178\n",
      "(1329, 69)\n",
      "1262237382.7285686\n",
      "(1369, 69)\n",
      "426236135.7211549\n"
     ]
    }
   ],
   "source": [
    "skf1 = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "    print(X_train.shape)\n",
    "    r = RandomForestRegressor(100)\n",
    "    r.fit(X_train,y_train)\n",
    "    y_pred = r.predict(X_test)\n",
    "    print(mse(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pandas.read_csv('dataset/test.csv')\n",
    "rf = RandomForestRegressor(100)\n",
    "rf.fit(X,y)\n",
    "test_df = test_df[cols]\n",
    "test_df = test_df.replace(d)\n",
    "test_df = test_df.fillna(test_df.median(axis=0))\n",
    "y_pred = rf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.concat([test_df['Id'],pandas.Series(y_pred,name='SalePrice')],axis=1)\n",
    "submission.to_csv('dataset/submission_1.csv',index=False)\n",
    "#submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "gbr = GBR()\n",
    "gbr.fit(X,y)\n",
    "y_pred = (gbr.predict(test_df)+rf.predict(test_df))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.concat([test_df['Id'],pandas.Series(y_pred,name='SalePrice')],axis=1)\n",
    "submission.to_csv('dataset/submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    \"loss\":[\"ls\",\"lad\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[100,150,200]\n",
    "    }\n",
    "reg = GridSearchCV(GBR(), parameters, cv=10, n_jobs=-1)\n",
    "reg.fit(X,y)\n",
    "y_pred = reg.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.concat([test_df['Id'],pandas.Series(y_pred,name='SalePrice')],axis=1)\n",
    "submission.to_csv('dataset/submission_4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
